{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning ProPicker\n",
    "\n",
    "In this notebook, we fine-tune ProPicker for picking ribosomes in the EMPIAR-10988 dataset. \n",
    "\n",
    "We use a crop of size `128x128x128` voxels extracted from the center of the `TS_029` tomogram and corresponding ground truth-annotations for fine-tuning. The crop contains 65 ribosomes which is less than 3% of the total number of ribosomes in the full `TS_029` tomogram.\n",
    "For early stopping, we use `128x128x128` a center crop from `TS_030` and corresponding ground-truth annotations (66 ribosomes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from propicker.clustering_and_picking import get_cluster_centroids_df\n",
    "from propicker.evaluation import evaluate_picks\n",
    "from propicker.paths import EMPIAR10988_BASE_DIR\n",
    "from propicker.data.preparation_functions.prepare_empiar10988 import read_empiar10988_coords, empiar10988_ts_to_slice_of_interest\n",
    "from propicker.inference.tomotwin import get_tomotwin_prompt_embeds_dict\n",
    "\n",
    "from propicker.utils.mrctools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup Conda Environment for Fine-Tuning\n",
    "\n",
    "Fine-tuning ProPicker works with our `DeepETPicker_ProPicker` fork of the [DeepETPicker](https://github.com/cbmi-group/DeepETPicker), which is integrated as a submodule. \n",
    "\n",
    "To run the fine-tuning code as described below, you need another conda environment (`deepetpicker`). You can create it by running\n",
    "```\n",
    "conda env create -f ./DeepETPicker_ProPicker/environment.yml\n",
    "conda activate deepetpicker\n",
    "pip install .\n",
    "```\n",
    "from the root of the ProPicker repository. The last step installs ProPicker in the `deepetpicker` conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prompt Extraction and Embedding\n",
    "\n",
    "For fine-tuning ProPicker, we first need to extract a prompt, which is used to condition the model and which we keep fixed during fine-tuning. We use the same prompt as for the clustering-based picking approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_id = \"TS_030\"\n",
    "\n",
    "tomo_file = f\"{EMPIAR10988_BASE_DIR}/tomograms/{ts_id}.rec\"\n",
    "ribo_coord_file = f\"{EMPIAR10988_BASE_DIR}/particle_lists/{ts_id}_cyto_ribosomes.csv\"\n",
    "\n",
    "# tomograms contain large emtpy regions, so we only consider the interesting part\n",
    "slice_of_interest = empiar10988_ts_to_slice_of_interest[ts_id]\n",
    "tomo = -1 * load_mrc_data(tomo_file).float()\n",
    "tomo = tomo[slice_of_interest].clone()\n",
    "\n",
    "\n",
    "coords = read_empiar10988_coords(ribo_coord_file)\n",
    "coords.Z -= slice_of_interest.start\n",
    "\n",
    "# extract all ribosomes as subtomos of shape (37, 37, 37); this shape is the one needed for the TomoTwin prompt encoder\n",
    "all_ribo_subtomos = []\n",
    "for coord in coords[[\"X\", \"Y\", \"Z\"]].values.astype(int):\n",
    "    x, y, z = coord\n",
    "    subtomo = tomo[\n",
    "        z-18:z+19,\n",
    "        y-18:y+19,\n",
    "        x-18:x+19\n",
    "    ]\n",
    "    # some ribosomes are at the edge of the tomogram, so we skip them\n",
    "    if not subtomo.shape == (37, 37, 37):\n",
    "        continue\n",
    "    all_ribo_subtomos.append(subtomo)\n",
    "    \n",
    "# you can choose any of the ribo subtomos as prompt\n",
    "prompt = all_ribo_subtomos[300]\n",
    "prompt_subtomos_dict = {\"cyto_ribosome\": prompt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We embed the prompt using tomotwin and save the embedding to disk, as we need it for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ProPicker/propicker/inference/tomotwin.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weightspth, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config:\n",
      "{'identifier': 'SiameseNet', 'network_config': {'output_channels': 32, 'dropout': 0.2, 'repeat_layers': 0, 'norm_name': 'GroupNorm', 'norm_kwargs': {'num_groups': 64, 'num_channels': 1024}, 'gem_pooling_p': 0}, 'train_config': {'loss': 'TripletLoss', 'tl_margin': 0.539, 'miner': True, 'miner_margin': 0.734, 'learning_rate': 5.945e-05, 'optimizer': 'Adam', 'weight_decay': 0, 'batchsize': 35, 'patience': 50, 'aug_train_shift_distance': 2}, 'distance': 'COSINE'}\n",
      "Successfully loaded model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing subtomos through TomoTwin: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt_embeds_dict = get_tomotwin_prompt_embeds_dict(\n",
    "    prompt_subtomos_dict=prompt_subtomos_dict, \n",
    "    tomotwin_model_file=\"./tomotwin.pth\", \n",
    "    device=\"cuda:0\", \n",
    "    batch_size=1, \n",
    "    out_file=\"./fixed_prompts_empiar10988.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fine-Tuning\n",
    "\n",
    "Code for fine-tuning is in `empiar10988_fine_tuning.py`. We recommend to have a look at the code as there are some hyperparameters that can be adjusted, then run the script in the `deepetpicker` environment:\n",
    "\n",
    "```bash\n",
    "conda activate deepetpicker\n",
    "python empiar10988_fine_tuning.py\n",
    "```\n",
    "\n",
    "With the current settings, the script fine-tunes ProPicker on a crop of size `256x256x256` voxels (around ) extracted from the center of `TS_029`. A center crop of the same size taken from `TS_030` is used as validation set.\n",
    "\n",
    "Running the fine-tuning script will create a directory `fine_tuning_empiar10988/crop_delta=64`, which contains all outputs produced in hte process. You can monitor the fine-uning using TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inference with the Fine-Tuned Model\n",
    "\n",
    "Inference with the fine-tuned model is handled in `empiar10988_inference.py`, which must also be run in the `deepetpicker` environment:\n",
    "```bash\n",
    "python empiar10988_inference.py\n",
    "```\n",
    "\n",
    "**Important:** Before you can run the script, you have to adjust the path to the model checkpoint in the script itself.\n",
    "\n",
    "Within `fine_tuning_empiar10988/crop_delta=64/runs`, you can now find the `full_segmentation_output` directory which contains the full 3D segmentation mask of the test tomogram produced with the fine-tuned model. Let's have a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_901602/3220126412.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pred_locmap = torch.load(\"./fine_tuning_empiar10988/crop_delta=64/runs/train/train_ProPicker_BlockSize72_CELoss_MaxEpoch100_bs8_lr0.001_IP1_bg1_coord1_Softmax0_bn__TNNone/version_0/full_segmentation_output/TS_030.pt\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './fine_tuning_empiar10988/crop_delta=64/runs/train/train_ProPicker_BlockSize72_CELoss_MaxEpoch100_bs8_lr0.001_IP1_bg1_coord1_Softmax0_bn__TNNone/version_0/full_segmentation_output/TS_030.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_locmap \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine_tuning_empiar10988/crop_delta=64/runs/train/train_ProPicker_BlockSize72_CELoss_MaxEpoch100_bs8_lr0.001_IP1_bg1_coord1_Softmax0_bn__TNNone/version_0/full_segmentation_output/TS_030.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(pred_locmap[\u001b[38;5;241m100\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/envs/ppicker/lib/python3.11/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/envs/ppicker/lib/python3.11/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/envs/ppicker/lib/python3.11/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fine_tuning_empiar10988/crop_delta=64/runs/train/train_ProPicker_BlockSize72_CELoss_MaxEpoch100_bs8_lr0.001_IP1_bg1_coord1_Softmax0_bn__TNNone/version_0/full_segmentation_output/TS_030.pt'"
     ]
    }
   ],
   "source": [
    "pred_locmap = torch.load(\"./fine_tuning_empiar10988/crop_delta=64/runs/train/train_ProPicker_BlockSize72_CELoss_MaxEpoch75_bs8_lr0.001_IP1_bg1_coord1_Softmax0_bn__TNNone/version_0/full_segmentation_output/TS_030.pt\")\n",
    "plt.imshow(pred_locmap[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2199\n",
      "       X      Y    Z  size\n",
      "0  723.0   41.0  4.0  1120\n",
      "2  221.0   77.0  6.0  1218\n",
      "3  170.0  324.0  6.0  1592\n",
      "4  546.0  398.0  6.0  1984\n",
      "5  634.0   39.0  7.0   889\n"
     ]
    }
   ],
   "source": [
    "# binarization\n",
    "binarization_thresh = 0.5  # after fine-tuning the model is usually much more confident so you have to increase the binarization threshold to avoid overlapping particle clusters\n",
    "binary_locmap = pred_locmap > binarization_thresh\n",
    "\n",
    "# clustering\n",
    "cluster_centroids = get_cluster_centroids_df(binary_locmap)\n",
    "\n",
    "# size-based filtering\n",
    "ball_volume = 4/3 * torch.pi * (24/2)**3  \n",
    "min_cluster_size = 0.1 * ball_volume  \n",
    "max_cluster_size = 1.2 * ball_volume \n",
    "\n",
    "cluster_centroids_filt = cluster_centroids[\n",
    "    (min_cluster_size <= cluster_centroids[\"size\"]) & (cluster_centroids[\"size\"] <= max_cluster_size)\n",
    "]\n",
    "\n",
    "print(f\"Number of clusters: {len(cluster_centroids_filt)}\")\n",
    "print(cluster_centroids_filt.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cyto_ribosome': {'F1': 0.7032309533306741,\n",
       "  'Recall': 0.6334890406036651,\n",
       "  'Precision': 0.7902285970416854,\n",
       "  'TruePositiveRate': 0.6334890406036651,\n",
       "  'TP': 1763,\n",
       "  'FP': 468,\n",
       "  'FN': 1020}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see TUTORIAL1 for explanation of this\n",
    "bbox_size = 37\n",
    "coords[\"height\"] = coords[\"width\"] = coords[\"depth\"] = bbox_size\n",
    "cluster_centroids_filt[\"height\"] = cluster_centroids_filt[\"width\"] = cluster_centroids_filt[\"depth\"] = bbox_size\n",
    "cluster_centroids_filt[\"class\"] = \"cyto_ribosome\"\n",
    "\n",
    "evaluate_picks(\n",
    "    pred_positions=cluster_centroids_filt,\n",
    "    gt_positions=coords,\n",
    "    iou_thresh=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Fine-tuning ProPicker significantly improves the performance of the model on the EMPIAR-10988 dataset. The fine-tuned model has higher precison and recall but most improvements are in recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
